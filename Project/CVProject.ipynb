{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from random import randint\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "#Use GPU\n",
    "device= torch.device(\"cuda\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000, 28, 28])\n",
      "torch.Size([10000, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "#Read in files\n",
    "trainData=torch.load('mnist/train_data.pt')\n",
    "trainLabel=torch.load('mnist/train_label.pt')\n",
    "testData=torch.load('mnist/test_data.pt')\n",
    "testLabel=torch.load('mnist/test_label.pt')\n",
    "\n",
    "print(trainData.size())\n",
    "print(testData.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1307)\n",
      "tensor(0.3081)\n"
     ]
    }
   ],
   "source": [
    "#mean and std to normalize\n",
    "mean= trainData.mean()\n",
    "std= trainData.std()\n",
    "\n",
    "print(mean)\n",
    "print(std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CNN fucntion\n",
    "class CNN(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1,   50,  kernel_size=3,  padding=1 )\n",
    "        self.pool1  = nn.MaxPool2d(2,2)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(50,  100,  kernel_size=3,  padding=1 )\n",
    "        self.pool2 = nn.MaxPool2d(2,2)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(100,  200,  kernel_size=3,  padding=1 )\n",
    " \n",
    "        self.linear1 = nn.Linear(9800, 100)\n",
    "\n",
    "        self.linear2 = nn.Linear(100,10)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)        \n",
    "        x = self.pool1(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool2(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = F.relu(x)\n",
    "  \n",
    "        x = x.view(-1, 9800)\n",
    "        x = self.linear1(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.linear2(x)\n",
    "    \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "net=CNN()\n",
    "\n",
    "#Send to GPU\n",
    "net = net.to(device)\n",
    "mean=mean.to(device)\n",
    "std=std.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameters\n",
    "\n",
    "epochs = 30\n",
    "\n",
    "lossFunction = nn.CrossEntropyLoss()\n",
    "\n",
    "learningRate = 0.25 \n",
    "\n",
    "batchSize = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate Error\n",
    "def calcError( scores , labels ):\n",
    "\n",
    "    bs=scores.size(0)\n",
    "    predictedLabels = scores.argmax(dim=1)\n",
    "    indicator = (predictedLabels == labels)\n",
    "    numMatches=indicator.sum()\n",
    "    \n",
    "    return 1-numMatches.float()/bs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluation Function\n",
    "\n",
    "def evalTestData():\n",
    "\n",
    "    runningError=0\n",
    "    numBatches=0\n",
    "\n",
    "    for i in range(0,10000,batchSize):\n",
    "\n",
    "        miniBatchData =  testData[i:i+batchSize].unsqueeze(dim=1)\n",
    "        miniBatchLabel= testLabel[i:i+batchSize]\n",
    "\n",
    "        miniBatchData=miniBatchData.to(device)\n",
    "        miniBatchLabel=miniBatchLabel.to(device)\n",
    "        \n",
    "        inputs = (miniBatchData - mean)/std\n",
    "\n",
    "        scores=net( inputs ) \n",
    "\n",
    "        error = calcError( scores , miniBatchLabel)\n",
    "\n",
    "        runningError += error.item()\n",
    "\n",
    "        numBatches+=1\n",
    "\n",
    "\n",
    "    totalError = runningError/numBatches\n",
    "    print( 'error rate on test set =', totalError*100 ,'percent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch= 1 \t time= 0.11693048477172852 min \t lr= 0.25 \t loss= 0.26530257218888703 \t error= 8.419953798180197 percent\n",
      "error rate on test set = 1.3053797468354431 percent\n",
      " \n",
      "epoch= 2 \t time= 0.22628641923268636 min \t lr= 0.25 \t loss= 0.045241959190476674 \t error= 1.3748223085139097 percent\n",
      "error rate on test set = 0.9889240506329114 percent\n",
      " \n",
      "epoch= 3 \t time= 0.33521777391433716 min \t lr= 0.25 \t loss= 0.02887677943814538 \t error= 0.8767546112857648 percent\n",
      "error rate on test set = 0.9295886075949367 percent\n",
      " \n",
      "epoch= 4 \t time= 0.44418073892593385 min \t lr= 0.25 \t loss= 0.020686477886017428 \t error= 0.6663113006396588 percent\n",
      "error rate on test set = 1.0383702531645569 percent\n",
      " \n",
      "epoch= 5 \t time= 0.5538660287857056 min \t lr= 0.125 \t loss= 0.010076494273870612 \t error= 0.2804059972132701 percent\n",
      "error rate on test set = 0.7120253164556962 percent\n",
      " \n",
      "epoch= 6 \t time= 0.6637563506762186 min \t lr= 0.125 \t loss= 0.006982160362798268 \t error= 0.17823827292110875 percent\n",
      "error rate on test set = 0.7120253164556962 percent\n",
      " \n",
      "epoch= 7 \t time= 0.7747576832771301 min \t lr= 0.125 \t loss= 0.0055428851864485346 \t error= 0.13381751107254516 percent\n",
      "error rate on test set = 0.7318037974683544 percent\n",
      " \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-22dc31947cbc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mlossFunction\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mscores\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mminiBatchLabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    194\u001b[0m         \"\"\"\n\u001b[1;32m--> 195\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    196\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 99\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Training Loop\n",
    "\n",
    "start=time.time()\n",
    "\n",
    "for epoch in range(1,epochs):\n",
    "    \n",
    "    if not epoch%5:\n",
    "        learningRate = learningRate / 2\n",
    "    \n",
    "    #Optimizer Hyperparameter\n",
    "    optimizer=torch.optim.SGD( net.parameters() , lr=learningRate )\n",
    "        \n",
    "    runningLoss=0\n",
    "    runningError=0\n",
    "    numBatches=0\n",
    "    \n",
    "    shuffledIndices=torch.randperm(60000)\n",
    " \n",
    "    for count in range(0,60000,batchSize):\n",
    "    \n",
    "        optimizer.zero_grad()\n",
    "             \n",
    "        indices=shuffledIndices[count:count+batchSize]\n",
    "        miniBatchData =  trainData[indices].unsqueeze(dim=1)\n",
    "        miniBatchLabel=  trainLabel[indices]\n",
    "        \n",
    "        miniBatchData=miniBatchData.to(device)\n",
    "        miniBatchLabel=miniBatchLabel.to(device)\n",
    "        \n",
    "        inputs = (miniBatchData - mean)/std  \n",
    "        \n",
    "        inputs.requires_grad_()\n",
    "\n",
    "        scores=net( inputs ) \n",
    "\n",
    "        loss =  lossFunction( scores , miniBatchLabel) \n",
    "          \n",
    "        loss.backward()        \n",
    "        optimizer.step()\n",
    "        \n",
    "\n",
    "        # Calculate Error\n",
    "        \n",
    "        runningLoss += loss.detach().item()\n",
    "        \n",
    "        error = calcError( scores.detach() , miniBatchLabel)\n",
    "        runningError += error.item()\n",
    "        \n",
    "        numBatches+=1        \n",
    "    \n",
    "    \n",
    "    # Display average error\n",
    "    totalLoss = runningLoss/numBatches\n",
    "    totalError = runningError/numBatches\n",
    "    elapsed = (time.time()-start)/60\n",
    "    \n",
    "    print('epoch=',epoch, '\\t time=', elapsed,'min', '\\t lr=', learningRate  ,'\\t loss=', totalLoss , '\\t error=', \n",
    "          totalError*100 ,'percent')\n",
    "    evalTestData() \n",
    "    print(' ')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
